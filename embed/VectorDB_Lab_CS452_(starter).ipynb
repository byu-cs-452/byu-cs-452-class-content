{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/byu-cs-452/byu-cs-452-class-content/blob/main/embed/VectorDB_Lab_CS452_(starter).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4UOUNsUTsvcn"
      },
      "outputs": [],
      "source": [
        "# Download dataset from GitHub releases\n",
        "# Total download size: ~613 MB (raw_data: 29 MB, embeddings: 584 MB)\n",
        "\n",
        "import os\n",
        "\n",
        "print(\"Downloading dataset files...\")\n",
        "if not os.path.exists(\"raw_data.zip\"):\n",
        "  print(\"  → Downloading raw_data.zip (29 MB)...\")\n",
        "  !wget -q --show-progress https://github.com/byu-cs-452/byu-cs-452-class-content/releases/download/v1.0-lex-fridman-dataset/raw_data.zip\n",
        "  print(\"  ✓ raw_data.zip downloaded\")\n",
        "\n",
        "if not os.path.exists(\"embeddings.zip\"):\n",
        "  print(\"  → Downloading embeddings.zip (584 MB, this may take a minute)...\")\n",
        "  !wget -q --show-progress https://github.com/byu-cs-452/byu-cs-452-class-content/releases/download/v1.0-lex-fridman-dataset/embeddings.zip\n",
        "  print(\"  ✓ embeddings.zip downloaded\")\n",
        "\n",
        "print(\"✓ All files downloaded!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Unzip data files\n",
        "# This will extract batch_request.jsonl and embeddings.jsonl\n",
        "\n",
        "print(\"Extracting data files...\")\n",
        "!unzip -n raw_data.zip\n",
        "!unzip -n embeddings.zip\n",
        "print(\"✓ Extraction complete!\")\n",
        "print(\"\\nExtracted files:\")\n",
        "!ls -lh *.jsonl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SYDFzWfv4HLW"
      },
      "outputs": [],
      "source": [
        "# Install required libraries\n",
        "# Note: Specific versions ensure compatibility with the lab\n",
        "\n",
        "!pip install -q datasets==2.20.0 psycopg2-binary==2.9.9\n",
        "\n",
        "print(\"✓ Libraries installed successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import psycopg2\n",
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "print(\"✓ Libraries imported successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Option 1: Run this to set up a LOCAL PostgreSQL database in Colab\n",
        "# This will take ~2-3 minutes to complete\n",
        "\n",
        "# Configure database name\n",
        "DATABASE_NAME = \"embedding_project\"\n",
        "\n",
        "print(\"Setting up PostgreSQL locally (this takes ~2-3 minutes)...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(\"\\n[1/5] Installing PostgreSQL...\")\n",
        "!apt update > /dev/null 2>&1\n",
        "!apt install -y postgresql postgresql-contrib > /dev/null 2>&1\n",
        "\n",
        "print(\"[2/5] Starting PostgreSQL service...\")\n",
        "!service postgresql start\n",
        "\n",
        "print(\"[3/5] Creating database user...\")\n",
        "!sudo -u postgres psql -c \"CREATE USER root WITH SUPERUSER PASSWORD 'root'\" 2>/dev/null || echo \"  (User already exists)\"\n",
        "\n",
        "print(f\"[4/5] Creating database '{DATABASE_NAME}'...\")\n",
        "!sudo -u postgres psql -c \"CREATE DATABASE {DATABASE_NAME}\" 2>/dev/null || echo \"  (Database already exists)\"\n",
        "\n",
        "print(\"[5/5] Installing pgvector extension...\")\n",
        "!apt install -y postgresql-server-dev-all build-essential > /dev/null 2>&1\n",
        "!git clone --quiet --branch v0.8.0 https://github.com/pgvector/pgvector.git 2>/dev/null || echo \"  (Already cloned)\"\n",
        "!cd pgvector && make > /dev/null 2>&1 && make install > /dev/null 2>&1\n",
        "!sudo -u postgres psql -d {DATABASE_NAME} -c \"CREATE EXTENSION IF NOT EXISTS vector;\" 2>/dev/null\n",
        "\n",
        "CONNECTION = f\"postgresql://root:root@localhost:5432/{DATABASE_NAME}\"\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"✓ PostgreSQL setup complete!\")\n",
        "print(f\"✓ Connection string: {CONNECTION}\")\n",
        "print(\"\\nYou can now proceed with creating tables and loading data.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ukT4dY-z25XG"
      },
      "outputs": [],
      "source": [
        "# Option 2: Use TimescaleDB cloud service instead of local PostgreSQL\n",
        "# \n",
        "# If you prefer to use TimescaleDB (cloud-hosted):\n",
        "# 1. Sign up for a free trial at https://www.timescale.com/\n",
        "# 2. Create a new service\n",
        "# 3. Copy your connection string and paste it below\n",
        "# 4. Run this cell (and skip Cell 5 above)\n",
        "\n",
        "# Uncomment and add your connection string:\n",
        "# CONNECTION = \"postgresql://username:password@host:port/database\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gpp_3EuU3SN-"
      },
      "outputs": [],
      "source": [
        "# ⚠️  CAUTION: Use this to reset your database (deletes all data!)\n",
        "# Only run this if you want to start completely over\n",
        "\n",
        "import psycopg2\n",
        "\n",
        "DROP_TABLES = \"DROP TABLE IF EXISTS segment, podcast CASCADE\"\n",
        "\n",
        "# Uncomment the lines below to actually drop the tables:\n",
        "# with psycopg2.connect(CONNECTION) as conn:\n",
        "#     cursor = conn.cursor()\n",
        "#     cursor.execute(DROP_TABLES)\n",
        "#     conn.commit()\n",
        "#     print(\"✓ Tables dropped successfully. You can now recreate them.\")\n",
        "\n",
        "print(\"⚠️  Drop command is commented out for safety.\")\n",
        "print(\"   Uncomment the code above if you really want to reset the database.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZDxdvoP4Fov"
      },
      "outputs": [],
      "source": [
        "def fast_pg_insert(df: pd.DataFrame, connection: str, table_name: str, columns: List[str]) -> None:\n",
        "    \"\"\"\n",
        "    Inserts data from a pandas DataFrame into a PostgreSQL table using the COPY command for fast insertion.\n",
        "    Uses a temporary CSV file to avoid memory issues with large DataFrames.\n",
        "\n",
        "    Parameters:\n",
        "    df (pd.DataFrame): The DataFrame containing the data to be inserted.\n",
        "    connection (str): The connection string to the PostgreSQL database.\n",
        "    table_name (str): The name of the target table in the PostgreSQL database.\n",
        "    columns (List[str]): A list of column names that must exist in the DataFrame.\n",
        "                        Data will be inserted in this exact order.\n",
        "\n",
        "    Returns:\n",
        "    None\n",
        "    \"\"\"\n",
        "    if not columns:\n",
        "        raise ValueError(\"columns parameter cannot be empty\")\n",
        "    \n",
        "    # Validate that all required columns exist in the DataFrame\n",
        "    missing_cols = set(columns) - set(df.columns)\n",
        "    if missing_cols:\n",
        "        raise ValueError(f\"DataFrame is missing requested columns: {missing_cols}\\n\"\n",
        "                        f\"DataFrame has: {list(df.columns)}\")\n",
        "    \n",
        "    print(f\"Inserting {len(df):,} rows into '{table_name}' table...\")\n",
        "    print(f\"  Columns: {columns}\")\n",
        "    \n",
        "    conn = psycopg2.connect(connection)\n",
        "    csv_file = f\"{table_name}_temp.csv\"\n",
        "    \n",
        "    # Write only the specified columns to CSV file in the exact order specified\n",
        "    print(\"  → Writing to CSV file...\")\n",
        "    df[columns].to_csv(csv_file, sep=\";\", index=False, header=False)\n",
        "    \n",
        "    # Copy from file to database\n",
        "    print(\"  → Copying data to PostgreSQL...\")\n",
        "    with open(csv_file, 'r') as f:\n",
        "        with conn.cursor() as c:\n",
        "            c.copy_from(\n",
        "                file=f,\n",
        "                table=table_name,\n",
        "                sep=\";\",\n",
        "                columns=columns,\n",
        "                null=''\n",
        "            )\n",
        "    \n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "    \n",
        "    print(f\"✓ Successfully inserted {len(df):,} rows into '{table_name}'\")\n",
        "    print(f\"  (CSV file saved as '{csv_file}' for reference)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Y2HkhMZmHFC"
      },
      "source": [
        "Database Schema\n",
        "We will create a database with two tables: podcast and segment:\n",
        "\n",
        "**podcast**\n",
        "\n",
        "- PK: id\n",
        " - The unique podcast id found in the huggingface data (i,e., TRdL6ZzWBS0  is the ID for Jed Buchwald: Isaac Newton and the Philosophy of Science | Lex Fridman Podcast #214)\n",
        "- title\n",
        " - The title of podcast (ie., Jed Buchwald: Isaac Newton and the Philosophy of Science | Lex Fridman Podcast #214)\n",
        "\n",
        "**segment**\n",
        "\n",
        "- PK: id\n",
        " - the unique identifier for the podcast segment. This was created by concatenating the podcast idx and the segment index together (ie., \"0;1\") is the 0th podcast and the 1st segment\n",
        "This is present in the as the \"custom_id\" field in the `embedding.jsonl` and batch_request.jsonl files\n",
        "- start_time\n",
        " - The start timestamp of the segment\n",
        "- end_time\n",
        " - The end timestamp of the segment\n",
        "- content\n",
        " - The raw text transcription of the podcast\n",
        "- embedding\n",
        " - the 128 dimensional vector representation of the text\n",
        "- FK: podcast_id\n",
        " - foreign key to podcast.id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3EZuFdc9m9uP"
      },
      "outputs": [],
      "source": [
        "# Sample document:\n",
        "# {\n",
        "#   \"custom_id\": \"89:115\",\n",
        "#   \"url\": \"/v1/embeddings\",\n",
        "#   \"method\": \"POST\",\n",
        "#   \"body\": {\n",
        "#     \"input\": \" have been possible without these approaches?\",\n",
        "#     \"model\": \"text-embedding-3-large\",\n",
        "#     \"dimensions\": 128,\n",
        "#     \"metadata\": {\n",
        "#       \"title\": \"Podcast: Boris Sofman: Waymo, Cozmo, Self-Driving Cars, and the Future of Robotics | Lex Fridman Podcast #241\",\n",
        "#       \"podcast_id\": \"U_AREIyd0Fc\",\n",
        "#       \"start_time\": 484.52,\n",
        "#       \"stop_time\": 487.08\n",
        "#     }\n",
        "#   }\n",
        "# }\n",
        "\n",
        "# Sample embedding:\n",
        "# {\n",
        "#   \"id\": \"batch_req_QZBmHS7FBiVABxcsGiDx2THJ\",\n",
        "#   \"custom_id\": \"89:115\",\n",
        "#   \"response\": {\n",
        "#     \"status_code\": 200,\n",
        "#     \"request_id\": \"7a55eba082c70aca9e7872d2b694f095\",\n",
        "#     \"body\": {\n",
        "#       \"object\": \"list\",\n",
        "#       \"data\": [\n",
        "#         {\n",
        "#           \"object\": \"embedding\",\n",
        "#           \"index\": 0,\n",
        "#           \"embedding\": [\n",
        "#             0.0035960325,\n",
        "#             126 more lines....\n",
        "#             -0.093248844\n",
        "#           ]\n",
        "#         }\n",
        "#       ],\n",
        "#       \"model\": \"text-embedding-3-large\",\n",
        "#       \"usage\": {\n",
        "#         \"prompt_tokens\": 7,\n",
        "#         \"total_tokens\": 7\n",
        "#       }\n",
        "#     }\n",
        "#   },\n",
        "#   \"error\": null\n",
        "# }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bU6fFAwb5EYO"
      },
      "outputs": [],
      "source": [
        "# Create table statements that you'll write\n",
        "\n",
        "# TODO: Add create table statement\n",
        "CREATE_PODCAST_TABLE = \"\"\"\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# TODO: Add create table statement\n",
        "CREATE_SEGMENT_TABLE = \"\"\"\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "conn = psycopg2.connect(CONNECTION)\n",
        "# TODO: Create tables with psycopg2 (example: https://www.geeksforgeeks.org/executing-sql-query-with-psycopg2-in-python/)\n",
        "\n",
        "\n",
        "conn.commit()\n",
        "conn.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v81052OY5BKW"
      },
      "outputs": [],
      "source": [
        "# Learn about the data and extract it!\n",
        "# TODO: What data do we need?\n",
        "# TODO: What data is in the documents jsonl files?\n",
        "# TODO: What data is in the embedding jsonl files?\n",
        "# OPTIONAL: Take a look at the original hugging face dataset\n",
        "# from datasets import load_dataset\n",
        "# ds = load_dataset(\"Whispering-GPT/lex-fridman-podcast\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Transform the data into a pandas data frame\n",
        "# TODO: Get some pandas data frames for our two tables so we can copy the data in!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the data into the database using fast_pg_insert (therwise inserting the 800k documents will take a very, very long time)\n",
        "# TODO Copy all the \"podcast\" data into the podcast postgres table!\n",
        "# TODO Copy all the \"segment\" data into the segment postgres table!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NvkG-51G5IDe"
      },
      "outputs": [],
      "source": [
        "## This script is used to query the database\n",
        "import os\n",
        "import psycopg2\n",
        "\n",
        "\n",
        "# Write your queries\n",
        "# Q1) What are the five most similar segments to segment \"267:476\"\n",
        "# Input: \"that if we were to meet alien life at some point\"\n",
        "# For each result return the segment raw text, embedding distance, the segment id, and the podcast name\n",
        "\n",
        "conn = psycopg2.connect(CONNECTION)\n",
        "cur = conn.cursor()\n",
        "cur.execute(\"\"\"\n",
        "\n",
        "\"\"\")\n",
        "for row in cur.fetchall():\n",
        "  print(row)\n",
        "\n",
        "conn.commit()\n",
        "conn.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dq8ePSfrw8Ix"
      },
      "outputs": [],
      "source": [
        "# Q2) What are the five most dissimilar segments to segment \"267:476\"\n",
        "# Input: \"that if we were to meet alien life at some point\"\n",
        "# For each result return the segment raw text, embedding distance, the segment id, and the podcast name\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dmTK02bZk3pF"
      },
      "outputs": [],
      "source": [
        "# Q3) What are the five most similar segments to segment '48:511'\n",
        "# Input: \"Is it is there something especially interesting and profound to you in terms of our current deep learning neural network, artificial neural network approaches and the whatever we do understand about the biological neural network.\"\n",
        "# For each result return the segment raw text, embedding distance, the segment id, and the podcast name\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jcfhAKKQk9rV"
      },
      "outputs": [],
      "source": [
        "# Q4) What are the five most similar segments to segment '51:56'\n",
        "# Input: \"But what about like the fundamental physics of dark energy? Is there any understanding of what the heck it is?\"\n",
        "# For each result return the segment raw text, embedding distance, the segment id, and the podcast name\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OT4yTTn4k_iX"
      },
      "outputs": [],
      "source": [
        "# Q5) For each of the following podcast segments, find the five most similar podcast episodes. Hint: You can do this by averaging over the embedding vectors within a podcast episode.\n",
        "\n",
        "#     a) Segment \"267:476\"\n",
        "\n",
        "#     b) Segment '48:511'\n",
        "\n",
        "#     c) Segment '51:56'\n",
        "\n",
        "# For each result return the Podcast title and the embedding distance\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_oKIVjn4lBYD"
      },
      "outputs": [],
      "source": [
        "# Q6) For podcast episode id = VeH7qKZr0WI, find the five most similar podcast episodes. Hint: you can do a similar averaging procedure as Q5\n",
        "\n",
        "# Input Episode: \"Balaji Srinivasan: How to Fix Government, Twitter, Science, and the FDA | Lex Fridman Podcast #331\"\n",
        "# For each result return the Podcast title and the embedding distance\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WBZVtZP4lDO2"
      },
      "source": [
        "# Deliverables\n",
        "\n",
        "Submit a **single PDF file** containing:\n",
        "\n",
        "1. **Your code** - Include all cells with your solutions (you can use File → Print in Colab)\n",
        "2. **Query results** - For each question (Q1-Q6), include:\n",
        "   - The SQL query you wrote\n",
        "   - The output/results from running the query\n",
        "   - A brief explanation if needed\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyOxHciU1SUrsmKA9h4KNIRr",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
